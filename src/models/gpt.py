import os
from openai import OpenAI
from dotenv import load_dotenv
from src.helpers.json_utils import write_to_json  # Import the JSON function

# Load environment variables from a .env file
load_dotenv()

# Initialize the OpenAI client using the API key
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def get_gpt_response(prompt):
    """
    Send a prompt to the GPT model and return its response.

    :param prompt: The text prompt to be sent to the GPT model.
    :return: The response generated by the model, stripped of extra whitespace.
    """

    # Create a chat completion using the specified model
    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "user",  # Define the role of the message as 'user'
                "content": prompt,  # Send the user input (prompt) to the model
            }
        ],
    )
    # Return the response generated by the model, stripping any extra whitespace
    return completion.choices[0].message.content.strip()


def process_gpt_prompts(input_file, output_file, num_repeats):
    """
    Process prompts from an input file, get GPT responses, and save results to a JSON file.

    :param input_file: Path to the input file containing prompts (one per line).
    :param output_file: Path to the output file where results will be saved.
    :param num_repeats: Number of times to repeat each prompt for processing.
    """

    # Read prompts from the input file, assuming one prompt per line
    with open(input_file, "r") as file:
        prompts = file.readlines()

    results = []  # Initialize an empty list to store results
    total_prompts = len(prompts)  # Total number of prompts in the file
    total_tasks = (
        total_prompts * num_repeats
    )  # Total number of tasks to process (prompts * repetitions)

    try:
        # Loop through each prompt in the file
        for index, prompt in enumerate(prompts):
            # Strip leading/trailing whitespace from the prompt
            prompt = prompt.strip()
            if not prompt:
                continue  # Skip empty lines

            # Repeat the prompt processing for the specified number of times (num_repeats)
            for repeat in range(num_repeats):
                # Get the response from the GPT model for the current prompt
                response = get_gpt_response(prompt)

                # Store the result in the format: [Prompt Number, Repeat Number, Prompt, Response]
                results.append([index + 1, repeat + 1, prompt, response])

                # Calculate the current task number and print progress
                current_task = (index * num_repeats) + repeat + 1
                print(
                    f"GPT: Processing Prompt {index + 1}/{total_prompts}, Repetition {repeat + 1}/{num_repeats} ({current_task}/{total_tasks} tasks completed)"
                )

    finally:
        # Ensure results are written to the JSON file even if an error occurs
        write_to_json(output_file, results)
